{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import mne_bids\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_path = '/home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/sub-002/eeg/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/sub-002/eeg/sub-002_task-FaceRecognition_eeg.fdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-35c9b2b529be>:1: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne_bids.read._read_raw(os.path.join(eeg_path,'sub-002_task-FaceRecognition_eeg.set'))\n"
     ]
    }
   ],
   "source": [
    "raw = mne_bids.read._read_raw(os.path.join(eeg_path,'sub-002_task-FaceRecognition_eeg.set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading channel info from /home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/sub-002/eeg/sub-002_task-FaceRecognition_channels.tsv.\n"
     ]
    }
   ],
   "source": [
    "channels_fname = os.path.join(eeg_path,'sub-002_task-FaceRecognition_channels.tsv')\n",
    "bids_fname = 'sub-002_task-FaceRecognition_channels/'\n",
    "raw = mne_bids.read._handle_channels_reading(channels_fname,bids_fname,raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading electrode coords from /home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/sub-002/eeg/sub-002_task-FaceRecognition_channels.tsv.\n",
      "The read in electrodes file is: \n",
      " OrderedDict([('name', ['EEG001', 'EEG002', 'EEG003', 'EEG004', 'EEG005', 'EEG006', 'EEG007', 'EEG008', 'EEG009', 'EEG010', 'EEG011', 'EEG012', 'EEG013', 'EEG014', 'EEG015', 'EEG016', 'EEG017', 'EEG018', 'EEG019', 'EEG020', 'EEG021', 'EEG022', 'EEG023', 'EEG024', 'EEG025', 'EEG026', 'EEG027', 'EEG028', 'EEG029', 'EEG030', 'EEG031', 'EEG032', 'EEG033', 'EEG034', 'EEG035', 'EEG036', 'EEG037', 'EEG038', 'EEG039', 'EEG040', 'EEG041', 'EEG042', 'EEG043', 'EEG044', 'EEG045', 'EEG046', 'EEG047', 'EEG048', 'EEG049', 'EEG050', 'EEG051', 'EEG052', 'EEG053', 'EEG054', 'EEG055', 'EEG056', 'EEG057', 'EEG058', 'EEG059', 'EEG060', 'EEG061', 'EEG062', 'EEG063', 'EEG064', 'EEG065', 'EEG066', 'EEG067', 'EEG068', 'EEG069', 'EEG070', 'EEG071', 'EEG072', 'EEG073', 'EEG074']), ('type', ['EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'HEOG', 'VEOG', 'EKG', 'EKG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG']), ('units', ['microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'n/a', 'n/a', 'n/a', 'n/a', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV', 'microV'])])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-be609de9cd2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcoords_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sub-002_task-FaceRecognition_coordsystem.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne_bids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_electrodes_reading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoords_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/eegtorch/lib/python3.6/site-packages/mne_bids/read.py\u001b[0m in \u001b[0;36m_handle_electrodes_reading\u001b[0;34m(electrodes_fname, coord_frame, raw, verbose)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# convert coordinates to float and create list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     ch_names_raw = [x for i, x in enumerate(ch_names_raw)\n\u001b[0m\u001b[1;32m    205\u001b[0m                     if electrodes_dict['x'][i] != \"n/a\"]\n\u001b[1;32m    206\u001b[0m     electrodes_dict['x'] = [float(x) for x in electrodes_dict['x']\n",
      "\u001b[0;32m~/anaconda3/envs/eegtorch/lib/python3.6/site-packages/mne_bids/read.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# convert coordinates to float and create list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     ch_names_raw = [x for i, x in enumerate(ch_names_raw)\n\u001b[0;32m--> 205\u001b[0;31m                     if electrodes_dict['x'][i] != \"n/a\"]\n\u001b[0m\u001b[1;32m    206\u001b[0m     electrodes_dict['x'] = [float(x) for x in electrodes_dict['x']\n\u001b[1;32m    207\u001b[0m                             if x != \"n/a\"]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "electrodes_fname = os.path.join(eeg_path,'sub-002_task-FaceRecognition_channels.tsv')\n",
    "coords_frame = os.path.join(eeg_path,'sub-002_task-FaceRecognition_coordsystem.json')\n",
    "verbose = 1\n",
    "raw = mne_bids.read._handle_electrodes_reading(channels_fname,coords_frame,raw,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading events from /home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/sub-002/eeg/sub-002_task-FaceRecognition_events.tsv.\n"
     ]
    }
   ],
   "source": [
    "events_fname = os.path.join(eeg_path,'sub-002_task-FaceRecognition_events.tsv')\n",
    "raw = mne_bids.read._handle_events_reading(events_fname,raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-13d63f1901a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbids_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sub-002_task-FaceRecognition_eeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbids_root\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'/home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmne_bids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_bids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids_fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbids_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/eegtorch/lib/python3.6/site-packages/mne_bids/read.py\u001b[0m in \u001b[0;36mread_raw_bids\u001b[0;34m(bids_fname, bids_root, extra_params, verbose)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mbids_raw_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbids_basename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mbids_fpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids_raw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c,rf*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids_raw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bids_fname = 'sub-002_task-FaceRecognition_eeg'\n",
    "bids_root= '/home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/'\n",
    "mne_bids.read.read_raw_bids(bids_fname,bids_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to EEG files\n",
    "eeg_path = '/home/localadmin/Documents/research/2_projects/CMP_EEG/ds002718-cmpeeg/sub-002/eeg/' \n",
    "    \n",
    "eeg_fname = os.path.join(eeg_path,'sub-002_task-FaceRecognition_eeg.set')\n",
    "\n",
    "# Load EEG data into a 3d array with shape (#trials, #electrodes, # samples)\n",
    "epochs = mne.read_epochs_eeglab(eeg_fname,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

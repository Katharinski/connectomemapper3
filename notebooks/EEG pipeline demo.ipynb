{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7bc6b5",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how the newly implemented EEG pipeline can be called from command line. \n",
    "\n",
    "It is important to note that cmp _does not_ include preprocessing, so it is expected that you have your data ready to be analyzed. \n",
    "\n",
    "For visualization purposes, we are using subject 1 from the \"VEPCON\" dataset, available at ..., however, note that non-defaced MRIs were used to create the inverse solutions, as defacing creates distortions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# BIDS import\n",
    "from bids import BIDSLayout\n",
    "\n",
    "# CMP imports\n",
    "import cmp.project\n",
    "from cmp.info import __version__, __copyright__\n",
    "from cmtklib.util import print_error, print_blue, print_warning\n",
    "\n",
    "import warnings\n",
    "\n",
    "# imports for this notebook\n",
    "import pdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from cmtklib.bids.io import __nipype_directory__\n",
    "from IPython.display import SVG, display\n",
    "import mne\n",
    "import mne_connectivity as mnec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf728d4",
   "metadata": {},
   "source": [
    "First, we need to set up out cmp project with user-defined arguments. This is usually done using parser, but we do it manually here for demo purposes.\n",
    "\n",
    "A call from the CLI looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''connectomemapper3 --participant_label sub-01 --anat_pipeline_config /home/katharina/data/DS003_BIDS/code/ref_anatomical_config.json --eeg_pipeline_config /home/katharina/data/DS003_BIDS/code/ref_mne_eeg_config.json --bids_dir /home/katharina/data/DS003_BIDS --output_dir /home/katharina/data/DS003_BIDS/derivatives'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have arguments:\n",
    "bids_dir = '/home/katharina/data/DS003_BIDS'\n",
    "output_dir = '/home/katharina/data/DS003_BIDS/derivatives'\n",
    "participant_label = 'sub-01'\n",
    "anat_pipeline_config = '/home/katharina/data/DS003_BIDS/code/ref_anatomical_config.json'\n",
    "\n",
    "# we will first demonstrate the MNE-based pipeline\n",
    "eeg_pipeline_config = '/home/katharina/data/DS003_BIDS/code/ref_mne_eeg_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9cfaa",
   "metadata": {},
   "source": [
    "The eeg pipeline config .json file contains information that cmp needs to correctly load EEG data and associated information like electrode positions, names of conditions, which parcellation to use, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717afa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize project\n",
    "project = cmp.project.ProjectInfo()\n",
    "project.base_directory = os.path.abspath(bids_dir)\n",
    "project.output_directory = os.path.abspath(output_dir)\n",
    "project.subjects = [\"{}\".format(participant_label)]\n",
    "project.subject = \"{}\".format(participant_label)\n",
    "# anatomical pipeline is always run\n",
    "project.anat_config_file = os.path.abspath(anat_pipeline_config)\n",
    "# in our case, we do not have sessions\n",
    "project.subject_sessions = [\"\"]\n",
    "project.subject_session = \"\"\n",
    "# check for BIDS layout\n",
    "bids_layout = BIDSLayout(project.base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts of connectomemapper3.py that are relevant here\n",
    "\n",
    "# process the anatomical pipeline (e.g. to get Freesurfer derivatives necessary for MNE pipeline)\n",
    "# this takes a while when done for the first time (several hours for one subject)\n",
    "anat_pipeline = cmp.project.init_anat_project(project, False)\n",
    "if anat_pipeline is not None:\n",
    "    # check if inputs to anatomical pipeline are valid\n",
    "    anat_valid_inputs = anat_pipeline.check_input(bids_layout, gui=False)\n",
    "    if anat_valid_inputs:\n",
    "        print(\">> Process anatomical pipeline\")\n",
    "        anat_pipeline.process()\n",
    "    else:\n",
    "        print_error(\"  .. ERROR: Invalid inputs\")\n",
    "        exit_code = 1\n",
    "anat_valid_outputs, msg = anat_pipeline.check_output()\n",
    "project.freesurfer_subjects_dir = anat_pipeline.stages['Segmentation'].config.freesurfer_subjects_dir\n",
    "project.freesurfer_subject_id = anat_pipeline.stages['Segmentation'].config.freesurfer_subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process EEG pipeline\n",
    "project.eeg_config_file = os.path.abspath(eeg_pipeline_config)\n",
    "if anat_valid_outputs:\n",
    "    eeg_valid_inputs, eeg_pipeline = cmp.project.init_eeg_project(project, bids_layout, False)\n",
    "    if eeg_pipeline is not None:\n",
    "        eeg_pipeline.parcellation_scheme = anat_pipeline.parcellation_scheme\n",
    "        eeg_pipeline.atlas_info = anat_pipeline.atlas_info\n",
    "\n",
    "        if eeg_valid_inputs:\n",
    "            print(\">> Process EEG pipeline\")\n",
    "            eeg_pipeline.process()\n",
    "        else:\n",
    "            print(\"  .. ERROR: Invalid inputs\")\n",
    "            exit_code = 1\n",
    "else:\n",
    "    print_error(f'  .. ERROR: Invalid anatomical outputs for eeg pipeline')\n",
    "    print_error(f'{msg}')\n",
    "    exit_code = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58970fdc",
   "metadata": {},
   "source": [
    "Let's have a closer look at the outputs that the EEG pipeline produces.\n",
    "\n",
    "First of all: Connectomemapper works in such a way that the pipeline is first assembled and only afterwards, it is executed. During the assembly stage, input and output variables are connected and cmp produces a graph that visualizes this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b969143",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_svg = os.path.join(output_dir,__nipype_directory__,participant_label,'eeg_pipeline','graph.svg')\n",
    "display(SVG(filename=path_to_svg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ffaad",
   "metadata": {},
   "source": [
    "Apart from the input (\"datasource\") and output (\"eeg sinker\") nodes that are apart, you can see three blue boxes that represent the stages of the pipeline flow (preparer, loader, inverse solution). Each of the stages, again, has an input and and output node, as well as several nodes representing processing steps. Each processing step has its own \"interface\" which you can find in cmtklib/interfaces.\n",
    "\n",
    "In the following, we will go over the interfaces and show what output they produce. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19804780",
   "metadata": {},
   "source": [
    "# Preparing stage\n",
    "\n",
    "Let's first have a look at the information given via the config file regarding this stage: \n",
    "\n",
    ">     \"eeg_preparing_stage\": {\n",
    "        \"eeg_format\": \".set\",\n",
    "        \"epochs\": \"sub-01_task-faces_desc-preproc_eeg.set\",\n",
    "        \"invsol_format\": \"mne-sLORETA\",\n",
    "        \"parcellation\": {\n",
    "            \"label\": \"lausanne2008\", \n",
    "            \"desc\": \"\",\n",
    "            \"suffix\": \"scale1\"\n",
    "        },        \n",
    "        \"number_of_threads\": 1,\n",
    "        \"EEG_params\": {\n",
    "            \"expe_name\": \"faces\",\n",
    "            \"EEG_event_IDs\": {\n",
    "            \t\"SCRAMBLED\" : 0,\n",
    "            \t\"FACES\" : 1 \n",
    "            \t},\n",
    "            \"start_t\": -0.2, \n",
    "            \"end_t\" : 0.6\n",
    "        }\n",
    "    },\n",
    "\n",
    "\n",
    "The preparing stage has three processing steps: \n",
    "\n",
    "- eeglab2fif: reads eeglab data and converts them to MNE format (.fif file extension)\n",
    "- createsrc: creates the dipole locations along the surface of the brain \n",
    "- createbem: creates the boundary element method\n",
    "\n",
    "**eeglab2fif**\n",
    "\n",
    "If your data are not already in MNE format (.fif file extension), they have to be read and re-saved. The eeglab2fif interface does this for EEGLAB-format data (.set file extension). The interface produces a file named sub-01_epo.fif in the derivatives/cmp-v3.0.2 folder. Critically, the saved epochs contain a montage, i.e. the sensor locations which have to be supplied in a file names sub-01.xyz inside the subject's EEGLAB derivatives folder (derivatives/eeglab/sub-01/eeg/sub-01.xyz). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the EEG data\n",
    "with warnings.catch_warnings(): # suppress some irrelevant warnings coming from mne.read_epochs_eeglab()\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    epochs_eeglab = mne.read_epochs_eeglab(os.path.join(output_dir,'eeglab',\\\n",
    "                                participant_label,'eeg',participant_label+'_task-faces_desc-preproc_eeg.set')) # sub-01_FACES_250HZ_prepd.set\n",
    "\n",
    "# eeglab2fif removes a baseline and crops the epochs according to parameters start_t and end_t in config file\n",
    "start_t = -0.2\n",
    "end_t = 0.6\n",
    "epochs_eeglab.apply_baseline((start_t,0))\n",
    "epochs_eeglab.crop(tmin=start_t,tmax=end_t)\n",
    "evoked_eeglab = epochs_eeglab.average().pick('eeg')\n",
    "\n",
    "# compare to what eeglab2fif saved\n",
    "epochs_mne = mne.read_epochs(os.path.join(output_dir,'cmp-v3.0.2',\\\n",
    "                                participant_label,'eeg',participant_label+'_epo.fif'))\n",
    "evoked_mne = epochs_mne.average().pick('eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ee16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure()\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "_=evoked_mne.plot(time_unit='s')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "_=evoked_eeglab.plot(time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341caa83",
   "metadata": {},
   "source": [
    "**createsrc**\n",
    "\n",
    "MNE is able to create volume- and surface-based source spaces, but in our pipeline, we use surface-based only. In order to do this, MNE takes advantage of the Freesurfer-created outputs in the freesurfer-6.0.1 derivatives directory. \n",
    "\n",
    "**createbem**\n",
    "\n",
    "The BEM (boundary element model) is the head model we use, in our case, it is based on the individual's structural MRI and, again, related freesufer derivatives. Its creation consists of two steps. First, the necessary surfaces are extracted using mne.bem.make_watershed_bem: brain, inner skull, outer skull, and outer skin. The surfaces are saved in the subject's freesurfer-directory in a new folder bem/watershed. Second, the model itself is created using mne.make_bem_model and mne.make_bem_solution. In this step, the surfaces and the tissue conductivities between the surfaces are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the BEM surfaces and source space\n",
    "src = mne.read_source_spaces(os.path.join(output_dir,'cmp-v3.0.2',\\\n",
    "                                participant_label,'eeg',participant_label+'_src.fif'))\n",
    "# plot will appear in separate window\n",
    "%matplotlib qt \n",
    "# lines are the surfaces, pink dots are the sources (dipoles)\n",
    "_=mne.viz.plot_bem(subject=participant_label, subjects_dir=project.freesurfer_subjects_dir,\n",
    "                 brain_surfaces='white', src=src, orientation='sagittal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06bae5",
   "metadata": {},
   "source": [
    "# loader stage\n",
    "\n",
    "During the preparer stage, we have told cmp which file extensions and keywords to look for that are going to be used in the actual inverse solution. Using nipype's \"BIDS datagrabber\", it gathers the necessary inputs in this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d4d63",
   "metadata": {},
   "source": [
    "# inverse solution stage\n",
    "\n",
    "The only implemented inverse solution algorithm right now is sLORETA. \n",
    "\n",
    "This stage has again three processing steps: \n",
    "\n",
    "- createfwd: creates the forward solution (leadfield) from the BEM and the source space\n",
    "- createcov: creates the noise covariance matrix from the data\n",
    "- invsol_MNE: creates the actual inverse operator and applies it, resulting in ROI-time courses\n",
    "\n",
    "**createfwd**\n",
    "\n",
    "In creating the forward solution, the electrode positions need to be known. Remember, we added them to the MNE epochs during execution of eeglab2fif. However, in this step, it is crucial that those coordinates and the Freesurfer-surfaces used in the creation of the head model and the surface space are aligned. Any necessary transformations area passed to mne.make_forward_solution as the \"trans\" argument. Since we are using non-defaced MRIs, which are not exactly the same as the ones provided on OpenNeuro, we need this transform: \n",
    "\n",
    "```\n",
    "array([[ 1.   ,  0.   ,  0.   ,  0.   ],\n",
    "       [ 0.   ,  1.   ,  0.   , -0.009],\n",
    "       [ 0.   ,  0.   ,  1.   ,  0.011],\n",
    "       [ 0.   ,  0.   ,  0.   ,  1.   ]])\n",
    "```\n",
    "\n",
    "The transform has to be provided as sub-01-trans.fif and can be created manually or from a text-file using mne.write_trans. Here we assume that we have this file and can load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a081bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the alignment between MRI and electrode positions.\n",
    "trans = mne.read_trans(os.path.join(output_dir,'cmp-v3.0.2',\\\n",
    "                                participant_label,'eeg',participant_label+'-trans.fif'))\n",
    "mne.viz.plot_alignment(epochs_mne.info, trans=trans, subject=participant_label,\n",
    "                       subjects_dir=project.freesurfer_subjects_dir, dig=False,\n",
    "                       surfaces=dict(head=0.95), coord_frame='mri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca5e68",
   "metadata": {},
   "source": [
    "**createcov**\n",
    "\n",
    "MNE uses an estimate of signal to noise ratio in its creation of the inverse solution. For that, it considers the pre-stimulus period of the EEG recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the noise covariance.\n",
    "# go back to inline plotting\n",
    "%matplotlib inline \n",
    "noise_cov = mne.read_cov(os.path.join(output_dir,'cmp-v3.0.2',\\\n",
    "                                participant_label,'eeg',participant_label+'_noisecov.fif'))\n",
    "#fig_cov, fig_spectra = mne.viz.plot_cov(noise_cov, epochs_mne.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42302e",
   "metadata": {},
   "source": [
    "**invsol_MNE**\n",
    "\n",
    "Now, everything comes together to create the inverse operator, which is then applied to the EEG data to create source time courses. In the last step, the source time courses are converted to ROI-time courses according to the selected parcellation. \n",
    "\n",
    "The outputs that are necessary for this step to work were created in the previous processing steps, namely: \n",
    "\n",
    "- the EEG epochs in .fif-format\n",
    "- the electrode montage\n",
    "- the head model\n",
    "- the source point locations\n",
    "- the forward operator\n",
    "- the noise covariance\n",
    "\n",
    "First, the inverse operator is created using mne.minimum_norm.make_inverse_operator. We use the options \n",
    "\n",
    "```\n",
    "loose=1, depth=None, fixed=False\n",
    "```\n",
    "\n",
    "This means that we are obtaining full 3-dimensional dipoles whose orientation is not fixed or constrained to be (somewhat) orthogonal to surface; and we are not applying any depth weighting. The solution is written to a file sub-01-inv.fif in the same directory as the other outputs (derivatives/cmp-v3.0.2/sub-01/eeg). \n",
    "\n",
    "In a subsequent step in the same interface, this inverse operator is then applied to the epochs (not the evoked time course averaged over trials) using mne.minimum_norm.apply_inverse_epochs. \n",
    "\n",
    "The final step performed by this interface and by the EEG pipeline is to use mne.extract_label_time_course to create ROI-time courses according to mne.read_labels_from_annot. As given in the config file, we use \"lausanne2008\" scale 1, which is the Desikan-atlas. The time courses and the ROI-names are stored in sub-01_rtc_epo.pkl, i.e. a format that is not specific to MNE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the time courses.\n",
    "with open(os.path.join(output_dir,'cmp-v3.0.2',participant_label,'eeg',participant_label+'_rtc_epo.pkl'),'rb') as f:\n",
    "    rtc_epo = pickle.load(f)\n",
    "    # for some reason, MNE writes label time courses as lists. convert to numpy array\n",
    "    #rtc_epo['data'] = np.array(rtc_epo['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e064921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort labels to make the time courses look nicer\n",
    "N = len(rtc_epo['labels'])-2 # two \"unknown\" regions - do not plot\n",
    "sorting = list(np.arange(0,N,2))+list(np.arange(1,N,2)) # left and right always alternating\n",
    "# list of ROI names\n",
    "labels_list_left = [i.name for i in rtc_epo['labels'][0::2] if i.name!='unknown -lh']\n",
    "labels_list_right = [i.name for i in rtc_epo['labels'][1::2] if i.name!='unknown -rh']\n",
    "labels_list = labels_list_left+labels_list_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.imshow(np.mean(rtc_epo['data'][:,:-2,:],axis=0)[sorting,:],aspect='auto',extent=[-200,600,0,67],interpolation='None');\n",
    "plt.xlabel('ms')\n",
    "plt.ylabel('ROIs')\n",
    "plt.colorbar()\n",
    "locs = np.arange(0,N)\n",
    "_=plt.yticks(locs,labels_list[-1::-1] )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6514ee",
   "metadata": {},
   "source": [
    "# Connectivity measures\n",
    "\n",
    "Of course, the idea of cmp is to provide connectomes! This interface is not implemented yet in the pipeline, but with the ROI-time courses, it is easy to obtain functional connectivity matrices using MNE functions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25085c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import importlib\n",
    "\n",
    "sfreq = epochs_mne.info['sfreq']  # the sampling frequency\n",
    "con_methods = ['pli', 'wpli2_debiased', 'ciplv']\n",
    "\n",
    "label_ts = rtc_epo['data']\n",
    "\n",
    "con = mnec.spectral_connectivity(\n",
    "    label_ts, method=con_methods, mode='multitaper', sfreq=sfreq,\n",
    "    faverage=True, mt_adaptive=True, n_jobs=1)\n",
    "\n",
    "# con is a 3D array, get the connectivity for the first (and only) freq. band\n",
    "# for each method\n",
    "con_res = dict()\n",
    "for method, c in zip(con_methods, con):\n",
    "    con_res[method] = c.get_data(output='dense')[:, :, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fbc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [label.name for label in rtc_epo['labels']]\n",
    "\n",
    "lh_labels = [name for name in label_names if name.endswith('lh')]\n",
    "\n",
    "# Get the y-location of the label\n",
    "label_ypos = list()\n",
    "for name in lh_labels:\n",
    "    idx = label_names.index(name)\n",
    "    ypos = np.mean(rtc_epo['labels'][idx].pos[:, 1])\n",
    "    label_ypos.append(ypos)\n",
    "\n",
    "# Reorder the labels based on their location\n",
    "lh_labels = [label for (yp, label) in sorted(zip(label_ypos, lh_labels))]\n",
    "\n",
    "# For the right hemi\n",
    "rh_labels = [label[:-2] + 'rh' for label in lh_labels]\n",
    "\n",
    "# Save the plot order and create a circular layout\n",
    "node_order = list()\n",
    "node_order.extend(lh_labels[::-1])  # reverse the order\n",
    "node_order.extend(rh_labels)\n",
    "\n",
    "node_angles = mnec.viz.circular_layout(label_names, node_order, start_pos=90,\n",
    "                              group_boundaries=[0, len(label_names) / 2])\n",
    "\n",
    "# Plot the graph using node colors from the FreeSurfer parcellation. We only\n",
    "# show the 300 strongest connections.\n",
    "mnec.viz.plot_connectivity_circle(con_res['wpli2_debiased'], label_names, n_lines=300,\n",
    "                         node_angles=node_angles, node_colors='r',\n",
    "                         title='All-to-All Connectivity left-Auditory '\n",
    "                               'Condition (PLI)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
